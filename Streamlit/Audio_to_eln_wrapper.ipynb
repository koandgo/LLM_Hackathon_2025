{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U nemo_toolkit[\"asr\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M1KIqe5oWk_t",
        "outputId": "46b1c7f4-0443-4aa8-b265-cc76b2355804"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nemo_toolkit[asr]\n",
            "  Downloading nemo_toolkit-2.4.0-py3-none-any.whl.metadata (91 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m81.9/91.5 kB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.5/91.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec==2024.12.0 (from nemo_toolkit[asr])\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.34.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.0.2)\n",
            "Collecting onnx>=1.7.0 (from nemo_toolkit[asr])\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: protobuf~=5.29.5 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.9.0.post0)\n",
            "Collecting ruamel.yaml (from nemo_toolkit[asr])\n",
            "  Downloading ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (75.2.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.19.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (1.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (4.67.1)\n",
            "Collecting wget (from nemo_toolkit[asr])\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (1.17.3)\n",
            "Collecting braceexpand (from nemo_toolkit[asr])\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.8.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.8.1)\n",
            "Collecting jiwer<4.0.0,>=3.1.0 (from nemo_toolkit[asr])\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting kaldi-python-io (from nemo_toolkit[asr])\n",
            "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lhotse!=1.31.0 (from nemo_toolkit[asr])\n",
            "  Downloading lhotse-1.30.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.11.0)\n",
            "Collecting marshmallow (from nemo_toolkit[asr])\n",
            "  Downloading marshmallow-4.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting optuna (from nemo_toolkit[asr])\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (25.0)\n",
            "Collecting pyannote.core (from nemo_toolkit[asr])\n",
            "  Downloading pyannote_core-6.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pyannote.metrics (from nemo_toolkit[asr])\n",
            "  Downloading pyannote_metrics-4.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.25.1)\n",
            "Collecting pyloudnorm (from nemo_toolkit[asr])\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting resampy (from nemo_toolkit[asr])\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (1.16.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.13.1)\n",
            "Collecting sox<=1.5.0 (from nemo_toolkit[asr])\n",
            "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting texterrors<1.0.0 (from nemo_toolkit[asr])\n",
            "  Downloading texterrors-0.5.1.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whisper_normalizer (from nemo_toolkit[asr])\n",
            "  Downloading whisper_normalizer-0.1.12-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting num2words (from nemo_toolkit[asr])\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.22 (from nemo_toolkit[asr])\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (4.0.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (7.5.0)\n",
            "Collecting mediapy==1.1.6 (from nemo_toolkit[asr])\n",
            "  Downloading mediapy-1.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.2.2)\n",
            "Collecting sacremoses>=0.0.43 (from nemo_toolkit[asr])\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.2.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (3.1.1)\n",
            "Collecting fiddle (from nemo_toolkit[asr])\n",
            "  Downloading fiddle-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting hydra-core<=1.3.2,>1.3 (from nemo_toolkit[asr])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightning<=2.4.0,>2.2.1 (from nemo_toolkit[asr])\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: omegaconf<=2.3 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.17.1)\n",
            "Collecting torchmetrics>=0.11.0 (from nemo_toolkit[asr])\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting transformers<=4.52.0,>=4.51.0 (from nemo_toolkit[asr])\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.21.3)\n",
            "Collecting webdataset>=0.2.86 (from nemo_toolkit[asr])\n",
            "  Downloading webdataset-1.0.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting bitsandbytes==0.45.5 (from nemo_toolkit[asr])\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo_toolkit[asr]) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo_toolkit[asr]) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo_toolkit[asr]) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (3.19.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (1.1.9)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core<=1.3.2,>1.3->nemo_toolkit[asr]) (4.9.3)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer<4.0.0,>=3.1.0->nemo_toolkit[asr]) (8.2.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer<4.0.0,>=3.1.0->nemo_toolkit[asr])\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo_toolkit[asr]) (3.0.1)\n",
            "Collecting cytoolz>=0.10.1 (from lhotse!=1.31.0->nemo_toolkit[asr])\n",
            "  Downloading cytoolz-1.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting intervaltree>=3.1.0 (from lhotse!=1.31.0->nemo_toolkit[asr])\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo_toolkit[asr]) (0.9.0)\n",
            "Collecting lilcom>=1.1.0 (from lhotse!=1.31.0->nemo_toolkit[asr])\n",
            "  Downloading lilcom-1.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (1.1.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr])\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting packaging (from nemo_toolkit[asr])\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pytorch-lightning (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr])\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->nemo_toolkit[asr]) (0.43.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx>=1.7.0->nemo_toolkit[asr]) (0.5.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacremoses>=0.0.43->nemo_toolkit[asr]) (2024.11.6)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->nemo_toolkit[asr]) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->nemo_toolkit[asr]) (1.17.1)\n",
            "Collecting pybind11 (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting plac (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Downloading plac-1.4.5-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting loguru (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from texterrors<1.0.0->nemo_toolkit[asr]) (3.1.0)\n",
            "Collecting Levenshtein (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Downloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (3.4.0)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<=4.52.0,>=4.51.0->nemo_toolkit[asr])\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.52.0,>=4.51.0->nemo_toolkit[asr]) (0.6.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[asr]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[asr]) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[asr]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[asr]) (0.70.16)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from fiddle->nemo_toolkit[asr]) (1.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from fiddle->nemo_toolkit[asr]) (0.21)\n",
            "Collecting libcst (from fiddle->nemo_toolkit[asr])\n",
            "  Downloading libcst-1.8.4-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect->nemo_toolkit[asr]) (10.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect->nemo_toolkit[asr]) (4.4.4)\n",
            "Collecting docopt>=0.6.2 (from num2words->nemo_toolkit[asr])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->nemo_toolkit[asr]) (1.16.5)\n",
            "Collecting colorlog (from optuna->nemo_toolkit[asr])\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->nemo_toolkit[asr]) (2.0.43)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->nemo_toolkit[asr]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->nemo_toolkit[asr]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->nemo_toolkit[asr]) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->nemo_toolkit[asr]) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft->nemo_toolkit[asr]) (1.10.1)\n",
            "INFO: pip is looking at multiple versions of pyannote-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pyannote.core (from nemo_toolkit[asr])\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pyannote.core->nemo_toolkit[asr]) (2.4.0)\n",
            "INFO: pip is looking at multiple versions of pyannote-metrics to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pyannote.metrics (from nemo_toolkit[asr])\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo_toolkit[asr])\n",
            "  Downloading pyannote_database-6.0.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from pyloudnorm->nemo_toolkit[asr]) (1.0.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->nemo_toolkit[asr])\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[asr]) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[asr]) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[asr]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[asr]) (3.1.3)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[asr]) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[asr]) (4.4.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[asr]) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[asr]) (2.36.0)\n",
            "Collecting indic-numtowords (from whisper_normalizer->nemo_toolkit[asr])\n",
            "  Downloading indic_numtowords-1.1.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->nemo_toolkit[asr]) (1.3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->nemo_toolkit[asr]) (2.22)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from cytoolz>=0.10.1->lhotse!=1.31.0->nemo_toolkit[asr]) (0.12.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (3.12.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (3.2.3)\n",
            "Collecting pandas (from nemo_toolkit[asr])\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo_toolkit[asr])\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (0.17.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->nemo_toolkit[asr]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->nemo_toolkit[asr]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->nemo_toolkit[asr]) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->nemo_toolkit[asr]) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->nemo_toolkit[asr]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->nemo_toolkit[asr]) (3.0.2)\n",
            "Collecting jedi>=0.16 (from ipython->mediapy==1.1.6->nemo_toolkit[asr])\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (4.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.2.13)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (0.1.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapy-1.1.6-py3-none-any.whl (24 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading lhotse-1.30.3-py3-none-any.whl (851 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.4/851.4 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-1.0.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading fiddle-0.3.0-py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-4.0.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nemo_toolkit-2.4.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading whisper_normalizer-0.1.12-py3-none-any.whl (36 kB)\n",
            "Downloading cytoolz-1.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading lilcom-1.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (754 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.1/754.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading indic_numtowords-1.1.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcst-1.8.4-cp312-cp312-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plac-1.4.5-py2.py3-none-any.whl (22 kB)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Downloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sox, texterrors, kaldi-python-io, wget, docopt, intervaltree\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40036 sha256=a71d337bade1897622b98c03bb8a31c82d80021dceda77f6483a86899adbbb74\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c7/e7/baea1f7e79b9eb53addc81cc9b827424f4a7d8c9cc18c03659\n",
            "  Building wheel for texterrors (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for texterrors: filename=texterrors-0.5.1-cp312-cp312-linux_x86_64.whl size=1197639 sha256=36df0091a1f46916fede3fe3e02dd0802fbc9240ad13509dd242046f2d869453\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/8f/81/7df3770dce1fcd6dc49118d4b1766f99334dd2ff43848f3893\n",
            "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8953 sha256=27c5f67ec6847f314f4e62dafa9d4bc582da43216c0d5ef6d674c22c7a1a2d96\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/a9/7b/af1bff74047bf7dfde7040b8fbe968ebb2f68eeed71249a14c\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=fc6ef8c60831e003d35ef77059224ba49c4f7a6ac4d00770bb297d0252f9734a\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=9fe66a6c07c9fd2882ce07754b40df084a044442ed5a89d3d1369a2b1185e849\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26098 sha256=f477b13878e46da9bd95ea1a42e4cb22fd80cc56e0288b9a6f4587a9d489b197\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/c3/c3/238bf93c243597857edd94ddb0577faa74a8e16e9585896e83\n",
            "Successfully built sox texterrors kaldi-python-io wget docopt intervaltree\n",
            "Installing collected packages: wget, plac, docopt, braceexpand, sacremoses, ruamel.yaml.clib, rapidfuzz, pybind11, packaging, numpy, num2words, marshmallow, loguru, libcst, jedi, intervaltree, indic-numtowords, fsspec, cytoolz, colorlog, whisper_normalizer, webdataset, sox, ruamel.yaml, lilcom, lightning-utilities, Levenshtein, kaldi-python-io, jiwer, hydra-core, fiddle, tokenizers, texterrors, resampy, pyloudnorm, pyannote.core, optuna, onnx, transformers, torchmetrics, pyannote.database, nemo_toolkit, mediapy, lhotse, bitsandbytes, pytorch-lightning, pyannote.metrics, lightning\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.0\n",
            "    Uninstalling tokenizers-0.22.0:\n",
            "      Successfully uninstalled tokenizers-0.22.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.1\n",
            "    Uninstalling transformers-4.56.1:\n",
            "      Successfully uninstalled transformers-4.56.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Levenshtein-0.27.1 bitsandbytes-0.45.5 braceexpand-0.1.7 colorlog-6.9.0 cytoolz-1.0.1 docopt-0.6.2 fiddle-0.3.0 fsspec-2024.12.0 hydra-core-1.3.2 indic-numtowords-1.1.0 intervaltree-3.1.0 jedi-0.19.2 jiwer-3.1.0 kaldi-python-io-1.2.2 lhotse-1.30.3 libcst-1.8.4 lightning-2.4.0 lightning-utilities-0.15.2 lilcom-1.8.1 loguru-0.7.3 marshmallow-4.0.1 mediapy-1.1.6 nemo_toolkit-2.4.0 num2words-0.5.14 numpy-1.26.4 onnx-1.19.0 optuna-4.5.0 packaging-24.2 plac-1.4.5 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pybind11-3.0.1 pyloudnorm-0.1.1 pytorch-lightning-2.5.5 rapidfuzz-3.14.1 resampy-0.4.3 ruamel.yaml-0.18.15 ruamel.yaml.clib-0.2.12 sacremoses-0.1.1 sox-1.5.0 texterrors-0.5.1 tokenizers-0.21.4 torchmetrics-1.8.2 transformers-4.51.3 webdataset-1.0.2 wget-3.2 whisper_normalizer-0.1.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging"
                ]
              },
              "id": "f5de9d0b044d4f389e0307e618a29b8b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nemo.collections.asr as nemo_asr\n",
        "asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name=\"nvidia/parakeet-tdt-0.6b-v2\")\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "output = asr_model.transcribe(['salt_1.wav'], timestamps=True)\n",
        "# by default, timestamps are enabled for char, word and segment level\n",
        "word_timestamps = output[0].timestamp['word'] # word level timestamps for first sample\n",
        "segment_timestamps = output[0].timestamp['segment'] # segment level timestamps\n",
        "char_timestamps = output[0].timestamp['char'] # char level timestamps\n",
        "\n",
        "for stamp in segment_timestamps:\n",
        "    print(f\"{stamp['start']}s - {stamp['end']}s : {stamp['segment']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TQcCjn6zv-jn",
        "outputId": "132bed3f-8c57-4362-ac33-a0e095ddbc40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-09-12 22:54:19 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-09-12 22:54:20 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    use_lhotse: true\n",
            "    skip_missing_manifest_entries: true\n",
            "    input_cfg: null\n",
            "    tarred_audio_filepaths: null\n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    shuffle: true\n",
            "    num_workers: 2\n",
            "    pin_memory: true\n",
            "    max_duration: 40.0\n",
            "    min_duration: 0.1\n",
            "    text_field: answer\n",
            "    batch_duration: null\n",
            "    use_bucketing: true\n",
            "    bucket_duration_bins: null\n",
            "    bucket_batch_size: null\n",
            "    num_buckets: 30\n",
            "    bucket_buffer_size: 20000\n",
            "    shuffle_buffer_size: 10000\n",
            "    \n",
            "[NeMo W 2025-09-12 22:54:20 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    use_lhotse: true\n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    max_duration: 40.0\n",
            "    min_duration: 0.1\n",
            "    num_workers: 2\n",
            "    pin_memory: true\n",
            "    text_field: answer\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-09-12 22:54:20 nemo_logging:393] PADDING: 0\n",
            "[NeMo I 2025-09-12 22:54:26 nemo_logging:393] Using RNNT Loss : tdt\n",
            "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n",
            "[NeMo I 2025-09-12 22:54:26 nemo_logging:393] Using RNNT Loss : tdt\n",
            "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-09-12 22:54:26 nemo_logging:405] No conditional node support for Cuda.\n",
            "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
            "    Reason: CUDA is not available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-09-12 22:54:26 nemo_logging:393] Using RNNT Loss : tdt\n",
            "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-09-12 22:54:26 nemo_logging:405] No conditional node support for Cuda.\n",
            "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
            "    Reason: CUDA is not available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-09-12 22:54:37 nemo_logging:393] Model EncDecRNNTBPEModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--parakeet-tdt-0.6b-v2/snapshots/4f7f0088738aa056a90bdacbd6a0e22672b0f206/parakeet-tdt-0.6b-v2.nemo.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-93e74c87-08e5-427d-aae9-d6eb354ac718\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-93e74c87-08e5-427d-aae9-d6eb354ac718\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving salt_1.wav to salt_1 (1).wav\n",
            "User uploaded file \"salt_1 (1).wav\" with length 17653838 bytes\n",
            "[NeMo I 2025-09-12 22:55:12 nemo_logging:393] Timestamps requested, setting decoding timestamps to True. Capture them in Hypothesis object,                         with output[0][idx].timestep['word'/'segment'/'char']\n",
            "[NeMo I 2025-09-12 22:55:12 nemo_logging:393] Using RNNT Loss : tdt\n",
            "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-09-12 22:55:12 nemo_logging:405] No conditional node support for Cuda.\n",
            "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
            "    Reason: CUDA is not available\n",
            "Transcribing: 100%|██████████| 1/1 [01:56<00:00, 116.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.28s - 8.08s : This salt experiment started on September 11, 2025.\n",
            "8.72s - 12.8s : The first step was to weigh out the masses and the volumes.\n",
            "13.120000000000001s - 22.400000000000002s : Vial IDE1T1 had a volume of 1000 milliliters of water and 51 mg of salt.\n",
            "22.72s - 30.080000000000002s : Vial with the IDE2T2 had 1001 milliliters of water and 50 milligrams of salt.\n",
            "30.400000000000002s - 37.6s : Vial with the IDE3T3 had 1010 milliliters of water with 52 milligrams of salt.\n",
            "37.92s - 43.52s : The weighing started on June 20th, 2025 at 5.11 p.m.\n",
            "44.08s - 48.56s : and the weighing stopped at June 20th, 2025 at 5.15 p.m.\n",
            "49.2s - 58.480000000000004s : For the stock solutions, the stock solution had 1000 milliliters of water with 1,000 milliliters of ethanol and 50 milligrams of salt.\n",
            "58.800000000000004s - 65.04s : Weighing for the stock solution started on June 20th, 2025 at 5.19 p.m.\n",
            "65.52s - 69.60000000000001s : and stopped on June 20th, 2025 at 5.22 p.m.\n",
            "70.24s - 75.92s : and the stock solution was transferred on June 20th, 2025, 5.23 p.m.\n",
            "76.88s - 91.04s : For the reaction timeline, the reaction started at 5.30 Eastern Standard Time with Edition 1 happening at 6 o'clock, edition 2 at 6.30, edition 3 at 7, and then it was taken off the plate at 8 o'clock.\n",
            "91.36s - 101.92s : For the workup times, the vial ID E1T1 was worked up on August 7th, 2025, starting at 9 o'clock and ending at 9.01.\n",
            "102.48s - 111.36s : Vial with the IDE1T2 was worked up on August 7th, 2025, starting at 9.02 and ending at 9.03.\n",
            "111.84s - 120.64s : And vial with the IDE1T3 was worked up on August 7th, 2025, starting at 9.04 and ending at 9.05.\n",
            "121.92s - 125.60000000000001s : For the results, the masses of each vial ID were as follows.\n",
            "125.84s - 131.68s : E1T1 had a vile mass of 2001 and a crude vial mass of 2100.\n",
            "132.32s - 139.52s : Vial with the IDE1T2 had a vile mass of 2100 and a cruel vile mass of 2200.\n",
            "140.08s - 147.84s : And vial with the IDE1T3 had a vile mass of 2101 and a crude biomass of 2210.\n",
            "148.4s - 166.4s : For the characterization, vial IDE1T1 was characterized on August 8th, 2025 and 4 milligrams of the product was used for NMR and the SEC was taken on August 7, 2025 and 4 milligrams was used for the SEC.\n",
            "167.28s - 177.28s : E1T2 was characterized on August 7, 2025 and 5 milligrams of the product was used to measure NMR.\n",
            "177.6s - 183.44s : And the SEC was measured on August 7th, 2025 and 5 milligrams was used to characterize SEC.\n",
            "184.08s - 192.48000000000002s : For vial E1T3, the NMR was taken on August 7th, 2025 and 3 mg was used to measure NMR.\n",
            "192.8s - 199.52s : SEC was taken on August 7th, 2025 and 3 mg was used to characterize the SEC.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe the audio without timestamps\n",
        "transcription_output_no_timestamps = asr_model.transcribe(['salt_1.wav'], timestamps=False)\n",
        "\n",
        "# Extract only the text from the output and save to a new variable\n",
        "# The output is a list of Hypothesis objects, we assume there is at least one\n",
        "transcribed_text = transcription_output_no_timestamps[0].text\n",
        "\n",
        "# You can print the new variable to see the extracted text\n",
        "print(transcribed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqnHRb9l7jTn",
        "outputId": "cbd85a73-3c71-49da-e8d9-3bb9955c8f3a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [01:53<00:00, 113.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This salt experiment started on September 11, 2025. The first step was to weigh out the masses and the volumes. Vial IDE1T1 had a volume of 1000 milliliters of water and 51 mg of salt. Vial with the IDE2T2 had 1001 milliliters of water and 50 milligrams of salt. Vial with the IDE3T3 had 1010 milliliters of water with 52 milligrams of salt. The weighing started on June 20th, 2025 at 5.11 p.m. and the weighing stopped at June 20th, 2025 at 5.15 p.m. For the stock solutions, the stock solution had 1000 milliliters of water with 1,000 milliliters of ethanol and 50 milligrams of salt. Weighing for the stock solution started on June 20th, 2025 at 5.19 p.m. and stopped on June 20th, 2025 at 5.22 p.m. and the stock solution was transferred on June 20th, 2025, 5.23 p.m. For the reaction timeline, the reaction started at 5.30 Eastern Standard Time with Edition 1 happening at 6 o'clock, edition 2 at 6.30, edition 3 at 7, and then it was taken off the plate at 8 o'clock. For the workup times, the vial ID E1T1 was worked up on August 7th, 2025, starting at 9 o'clock and ending at 9.01. Vial with the IDE1T2 was worked up on August 7th, 2025, starting at 9.02 and ending at 9.03. And vial with the IDE1T3 was worked up on August 7th, 2025, starting at 9.04 and ending at 9.05. For the results, the masses of each vial ID were as follows. E1T1 had a vile mass of 2001 and a crude vial mass of 2100. Vial with the IDE1T2 had a vile mass of 2100 and a cruel vile mass of 2200. And vial with the IDE1T3 had a vile mass of 2101 and a crude biomass of 2210. For the characterization, vial IDE1T1 was characterized on August 8th, 2025 and 4 milligrams of the product was used for NMR and the SEC was taken on August 7, 2025 and 4 milligrams was used for the SEC. E1T2 was characterized on August 7, 2025 and 5 milligrams of the product was used to measure NMR. And the SEC was measured on August 7th, 2025 and 5 milligrams was used to characterize SEC. For vial E1T3, the NMR was taken on August 7th, 2025 and 3 mg was used to measure NMR. SEC was taken on August 7th, 2025 and 3 mg was used to characterize the SEC.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95952ed4",
        "outputId": "4372a2bf-8b0e-415b-b060-d2084e9cf571"
      },
      "source": [
        "# Save the transcribed text to a file\n",
        "output_filename = \"transcription.txt\"\n",
        "with open(output_filename, \"w\") as f:\n",
        "    f.write(transcribed_text)\n",
        "\n",
        "print(f\"Transcribed text saved to {output_filename}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed text saved to transcription.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CONFIG — edit me ===\n",
        "OPENAI_API_KEY = \"YOUR_API\"   # paste your key or set via environment\n",
        "MODEL_NAME      = \"gpt-4o-mini\"        # e.g., gpt-4o-mini, gpt-4.1-mini, etc.\n",
        "INPUT_TXT_PATH  = \"./transcription.txt\"   # path to your transcript\n",
        "OUTPUT_ELN_PATH = \"./name_model_output.eln\"   # desired output .eln filename\n",
        "RECORD_TITLE    = \"Record Name\"\n",
        "TIMEZONE        = \"America/New_York\"   # used in prompt normalization\n",
        "\n",
        "# Optional: pip install if needed\n",
        "#!pip install --upgrade openai\n",
        "#!pip install openai==0.28"
      ],
      "metadata": {
        "id": "_cez12D1G0Wb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, zipfile\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Prompt (system + user) ---\n",
        "SYSTEM_PROMPT = \"\"\"You are an expert Lab Notebook Compiler that converts messy, speech-style transcripts into a structured experiment record in clean HTML suitable for eLabFTW export. Do not invent or infer data; extract only what is said. Preserve sample IDs exactly (e.g., E8T1M2). Normalize number words to numerals (e.g., \"forty-two point five\" → 42.5). Write dates as YYYY-MM-DD and times as h:mm am/pm, appending timezone only if explicitly mentioned. Keep units exactly as stated; do not convert unless the transcript states a conversion. If a value is missing, ambiguous, or contradictory, leave the corresponding table cell blank. Maintain chronological order for events and work-ups; group repeated measurements by sample ID. Output ONLY raw HTML (no Markdown, no explanations). Use 18pt section headers and HTML tables with the exact formatting rules provided in HTML_INSTRUCTIONS.\n",
        "\"\"\"\n",
        "\n",
        "HTML_INSTRUCTIONS = \"\"\"Build an HTML document containing ONLY the sections below, in this order. Include a section only if the transcript provides at least one row for it.\n",
        "\n",
        "Formatting rules:\n",
        "• Section headers must be: <p><span style=\"font-size:18pt;\">{Title}</span></p>\n",
        "• Tables must be: <table style=\"min-width:25%;width:60%;border-width:1px;margin-left:0px;margin-right:auto;\" border=\"1\">\n",
        "• The first row of every table is a centered header row using: <td style=\"text-align:center;\">\n",
        "• Each subsequent row is one record extracted from the transcript.\n",
        "• Use plain <p> for single-line notes and <ul><li><p>…</p></li>…</ul> for bullet lists.\n",
        "• Leave cells blank for unknowns; do not write \"N/A\" or placeholders.\n",
        "• Preserve sample/replicate ordering as spoken (natural numeric sort within groups).\n",
        "\n",
        "1) Experiment Overview\n",
        "   Table columns: [Field, Value]\n",
        "   Suggested rows (only if present): Experiment title, Experiment start date, Operator, Project/Batch, Location/Lab.\n",
        "\n",
        "2) Materials / Reagents\n",
        "   Table columns: [Name/ID, Lot/Source, Amount, Units, Role/Notes]\n",
        "\n",
        "3) Samples / Vials / IDs\n",
        "   Table columns: [Sample/Vial ID, Group/Batch, Description/Label, Notes]\n",
        "\n",
        "4) Weigh / Volumes\n",
        "   Table columns: [Sample/Vial ID, Mass (g), Volume (mL), Notes]\n",
        "\n",
        "5) Solutions / Stocks (Composition)\n",
        "   Table columns: [Solution/ID, Component, Amount, Units, Final volume (mL), Notes]\n",
        "\n",
        "6) Setup / Conditions\n",
        "   Prefer a parameter table.\n",
        "   Table columns: [Parameter, Value, Units]\n",
        "   Examples: temperature setpoint, actual temperature, stir rate (rpm), atmosphere (N2/Ar), vessel, equipment.\n",
        "\n",
        "7) Procedure Timeline / Additions\n",
        "   Table columns: [Date, Time (local), Event]\n",
        "   Examples: reaction start, addition 1/2/3, quench, heat on/off, taken off plate.\n",
        "\n",
        "8) Work-up / Purification\n",
        "   Table columns: [Sample/ID, Date, Start (local), End (local), Step]\n",
        "   Steps could include filtration, wash, dry, transfer, etc.; leave \"Step\" blank if not spoken.\n",
        "\n",
        "9) Measurements — Mass Results (wide)\n",
        "   Table columns: [Sample/ID, Mass A (mg), Mass B (mg), Mass C (mg)]\n",
        "   If the transcript clearly names the mass fields (e.g., \"Vial mass (mg)\", \"Crude vial mass (mg)\"), use those as the headers instead of A/B/C.\n",
        "\n",
        "10) Measurements / Results (generic long format)\n",
        "    Table columns: [Sample/ID, Measurement, Value, Units, Method/Instrument]\n",
        "\n",
        "11) Characterization\n",
        "    Table columns: [Sample/ID, Technique, Date, Amount (mg), Notes]\n",
        "    Techniques may include NMR, SEC/GPC, UV-Vis, FTIR, MS, etc.\n",
        "\n",
        "12) Observations / Notes\n",
        "    Use a bullet list (<ul>…) with succinct sentences capturing qualitative observations, issues, and remarks.\n",
        "\n",
        "13) Next Steps / To-Do\n",
        "    Bullet list of stated follow-ups or planned changes.\n",
        "\n",
        "General parsing rules:\n",
        "• Convert spoken numbers to numerals (e.g., \"one thousand and ten\" → 1010; \"five point oh two\" → 5.02).\n",
        "• Keep precision as spoken; do not round or pad.\n",
        "• Times spoken without a date belong to the most recently referenced date in context.\n",
        "• If inconsistent data for the same field appears, prefer the most specific/latest mention; if still ambiguous, leave blank.\n",
        "• Do not add any narrative text outside of headers, tables, and lists.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "USER_PREFIX = (\n",
        "    \"Parse the transcript below into the specified HTML sections. Do not add sections beyond the list. \"\n",
        "    \"Leave cells blank when the transcript doesn't supply a value. Assume timezone '{tz}'.\\n\\n\"\n",
        ")\n",
        "\n",
        "def _random_hex(n=8):\n",
        "    import string, random\n",
        "    return ''.join(random.choices(string.hexdigits.lower(), k=n))\n",
        "\n",
        "def build_rocrate_with_html(html_body: str, title: str) -> dict:\n",
        "    ds_id = f\"./{title} - {_random_hex()}/\"\n",
        "    now_iso = datetime.now().astimezone().isoformat()\n",
        "    return {\n",
        "        \"@context\": \"https://w3id.org/ro/crate/1.1/context\",\n",
        "        \"@graph\": [\n",
        "            {\n",
        "                \"@id\": \"./\",\n",
        "                \"@type\": \"Dataset\",\n",
        "                \"name\": \"eLabFTW export\",\n",
        "                \"hasPart\": [{\"@id\": ds_id}],\n",
        "            },\n",
        "            {\n",
        "                \"@id\": ds_id,\n",
        "                \"@type\": \"Dataset\",\n",
        "                \"name\": title,\n",
        "                \"encodingFormat\": \"text/html\",\n",
        "                \"dateCreated\": datetime.now().astimezone().isoformat(),\n",
        "                \"text\": html_body,\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        "\n",
        "def write_eln_zip(meta: dict, out_path: Path) -> Path:\n",
        "    out_path = Path(out_path)\n",
        "    export_folder = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\") + \"-export\"\n",
        "    with zipfile.ZipFile(out_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
        "        z.writestr(f\"{export_folder}/ro-crate-metadata.json\", json.dumps(meta, ensure_ascii=False, indent=2))\n",
        "    return out_path\n",
        "\n",
        "def call_openai(model_name: str, system_prompt: str, html_instructions: str, transcript: str, api_key: str) -> str:\n",
        "    \"\"\"Call OpenAI and return HTML body string. Tries modern SDK, then legacy fallback.\"\"\"\n",
        "    try:\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=api_key)\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\",   \"content\": html_instructions},\n",
        "            {\"role\": \"user\",   \"content\": transcript},\n",
        "        ]\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "        )\n",
        "        return resp.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            import openai\n",
        "            openai.api_key = api_key\n",
        "            resp = openai.ChatCompletion.create(\n",
        "                model=model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\",   \"content\": html_instructions},\n",
        "                    {\"role\": \"user\",   \"content\": transcript},\n",
        "                ],\n",
        "                temperature=0,\n",
        "            )\n",
        "            return resp[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"OpenAI call failed: {e}\\nFallback also failed: {e2}\")\n",
        "\n",
        "# --- Run wrapper ---\n",
        "if not OPENAI_API_KEY or OPENAI_API_KEY == \"YOUR_API_KEY_HERE\":\n",
        "    raise SystemExit(\"Please set OPENAI_API_KEY in the config cell above before running.\")\n",
        "\n",
        "txt_path = Path(INPUT_TXT_PATH)\n",
        "if not txt_path.exists():\n",
        "    raise SystemExit(f\"Input TXT not found: {txt_path}\")\n",
        "\n",
        "raw = txt_path.read_text(encoding=\"utf-8\")\n",
        "user_prompt = USER_PREFIX.format(tz=TIMEZONE)\n",
        "full_user = user_prompt + \"\\nTRANSCRIPT:\\n<<<\\n\" + raw + \"\\n>>>\\n\"\n",
        "\n",
        "html_body = call_openai(MODEL_NAME, SYSTEM_PROMPT, HTML_INSTRUCTIONS, full_user, OPENAI_API_KEY)\n",
        "meta = build_rocrate_with_html(html_body, RECORD_TITLE)\n",
        "out_path = write_eln_zip(meta, Path(OUTPUT_ELN_PATH))\n",
        "print(f\"Saved ELN: {out_path}\")"
      ],
      "metadata": {
        "id": "pT2Xr0iBG94J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}